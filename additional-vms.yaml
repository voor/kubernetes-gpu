---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AWSMachineTemplate
metadata:
  name: gpus-md-4-nvidia
  namespace: default
  annotations:
    kapp.k14s.io/update-strategy: 'always-replace'
spec:
  template:
    spec:
      ami:
        id: ami-0728541f6e02e632d # My MAGIC AMI
      iamInstanceProfile: nodes.cluster-api-provider-aws.sigs.k8s.io
      instanceType: p2.xlarge
      sshKeyName: cluster-api-provider-aws
      rootVolume:
        size: 100
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: KubeadmConfigTemplate
metadata:
  name: gpus-md-4-tags
  namespace: default
  annotations:
    kapp.k14s.io/update-strategy: 'always-replace'
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            cloud-provider: aws
            # First one is based on the NVIDIA 
            node-labels: accelerator=nvidia-tesla-k80,gpu=yes,hardware=gpu
          name: '{{ ds.meta_data.local_hostname }}'
      useExperimentalRetryJoin: true
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: MachineDeployment
metadata:
  name: gpus-md-4
  namespace: default
spec:
  clusterName: gpus
  replicas: 1
  selector:
    matchLabels: null
  template:
    spec:
      rootDeviceSize: 100
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: KubeadmConfigTemplate
          name: gpus-md-4-tags
      clusterName: gpus
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
        kind: AWSMachineTemplate
        name: gpus-md-4-nvidia
      version: v1.17.3
